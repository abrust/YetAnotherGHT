{
	"name": "4 - PANDEMIC OPENROWSET queries",
	"properties": {
		"content": {
			"query": "-- CSV file contains header row; query uses HEADER_ROW = TRUE:\nSELECT \n\t*\nFROM OPENROWSET(\n    BULK 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.csv',\n    FORMAT = 'CSV',\n    PARSER_VERSION = '2.0',\n\tHEADER_ROW = TRUE) as [r]\n\n-- CSV file query doesn't use HEADER_ROW = TRUE, so set FIRSTROW to 2, and deal with generic column names\nSELECT \n\t*\nFROM OPENROWSET(\n    BULK 'https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/ecdc_cases/latest/ecdc_cases.csv',\n    FORMAT = 'CSV',\n    FIRSTROW = 2,\n    PARSER_VERSION = '2.0') as [r]\n\n-- Parquet file (schema inside):\nSELECT \n    TOP 1 *\nFROM  \n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/censusdatacontainer/release/us_population_county/year=20*/*.parquet',\n        FORMAT='PARQUET'\n    ) AS [r]\n\n-- CSV with no header row, but with schema (for two columns) specified\n-- Note the 1 and 4 at the end of the two column definitions, which indicate the ordinals of the corresponding columns\n-- Authtiction supplied through shared access signature, database scoped credential and external data source,\n-- the last of which is referenced in the DATA_SOURCE parameter of the OPENROWSET comamand\nCREATE DATABASE SCOPED CREDENTIAL [sqlondemand]\nWITH IDENTITY='SHARED ACCESS SIGNATURE',  \nSECRET = 'sv=2018-03-28&ss=bf&srt=sco&sp=rl&st=2019-10-14T12%3A10%3A25Z&se=2061-12-31T12%3A10%3A00Z&sig=KlSU2ullCscyTS0An0nozEpo4tO5JAgGBvw%2FJX2lguw%3D'\n\nCREATE EXTERNAL DATA SOURCE SqlOnDemandDemo WITH (\n    LOCATION = 'https://sqlondemandstorage.blob.core.windows.net',\n    CREDENTIAL = sqlondemand\n);\nGO;\n\nSELECT \n\t* \nFROM OPENROWSET(\n        BULK 'csv/population/population*.csv',\n        DATA_SOURCE = 'SqlOnDemandDemo',\n        FORMAT = 'CSV',\n        FIRSTROW = 1\n    )\nWITH (\n    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2 1,\n    [population] bigint 4\n) AS [r]\nGO;\n\nDROP EXTERNAL DATA SOURCE SqlOnDemandDemo\nDROP DATABASE SCOPED CREDENTIAL [sqlondemand]\n\n-- Schema specification for certain columns from Parquet file:\nSELECT \n    TOP 1 *\nFROM  \n    OPENROWSET(\n        BULK 'https://azureopendatastorage.blob.core.windows.net/censusdatacontainer/release/us_population_county/year=20*/*.parquet',\n        FORMAT='PARQUET'\n    )\nWITH (\n\t[stateName] VARCHAR (50),\n\t[population] bigint\n) AS [r]\n\n-- Read JSON file and specifcy schema\n-- Note use of lax and strict path modes\n-- SELECT \n--     TOP 1 *\n-- FROM  \n--     OPENROWSET(\n--         BULK 'https://azureopendatastorage.blob.core.windows.net/censusdatacontainer/release/us_population_county/year=20*/*.parquet',\n--         FORMAT='PARQUET'\n--     )\n-- WITH (\n-- \t--lax path mode samples\n-- \t[stateName] VARCHAR (50), -- this one works as column name casing is valid - it targets the same column as the next one\n-- \t[stateName_explicit_path] VARCHAR (50) '$.stateName', -- this one works as column name casing is valid\n-- \t[COUNTYNAME] VARCHAR (50), --  will contain NULLs only because of wrong casing - it targets the same column as the next one\n-- \t[countyName_explicit_path] VARCHAR (50) '$.COUNTYNAME', -- will contain NULLS  because of wrong casing and default path mode being lax\n\n-- \t--strict path mode samples\n-- \t[population] bigint 'strict $.population' -- this one works as column name casing is valid\n-- \t--,[population2] bigint 'strict $.POPULATION' -- this one fails because of wrong casing and strict path mode\n-- )\n-- AS [r]",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "Sample",
				"poolName": "Built-in"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}